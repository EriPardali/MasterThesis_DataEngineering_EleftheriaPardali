{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae382d5",
   "metadata": {},
   "source": [
    "### Feature Engineering Overview\n",
    "\n",
    "This notebook performs the feature engineering process on the *Loan Portfolio* dataset.  \n",
    "The objective is to transform and enrich the raw dataset prepared during the EDA stage to support subsequent KPI calculation and portfolio analysis.  \n",
    "Αll transformations are aimed at improving data quality, interpretability, and aggregation readiness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09871fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a4612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start shape: (9989, 23)\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "# Create a working copy\n",
    "df_eda = pd.read_csv(DATA_DIR / \"eda_processed.csv\")\n",
    "fe = df_eda.copy()\n",
    "print(\"Start shape:\", fe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc8692",
   "metadata": {},
   "source": [
    "### Ordinal Feature Encoding\n",
    "\n",
    "Ordinal variables such as **loan term**, **Employment length**, **grade**, and **sub-grade** were converted into numeric scales that preserve their inherent ranking.  \n",
    "This transformation enables consistent quantitative analysis, ensuring that the model interprets these features according to their natural order (e.g., longer terms imply higher duration risk, higher grades correspond to lower credit risk).  \n",
    "By maintaining their ordinal structure, the encoded variables support more meaningful feature interactions and improve downstream model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b51b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added (ordinal): ['term_months', 'emp_length_years', 'grade_ord', 'sub_grade_ord']\n",
      "Shape: (9989, 27)\n"
     ]
    }
   ],
   "source": [
    "#Ordinal encodings (term, emp_length, grade, sub_grade)\n",
    "\n",
    "# term → numeric months\n",
    "if 'term' in fe.columns:\n",
    "    fe['term_months'] = (\n",
    "        fe['term'].astype(str).str.extract(r'(\\d+)')[0].astype(float)\n",
    "    ).astype('float32')\n",
    "\n",
    "# Employment_length → years (e.g., \"< 1 year\" -> 0, \"10+ years\" -> 10)\n",
    "if 'Employment_length' in fe.columns:\n",
    "    def emp_len_to_years(x: str) -> float:\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)): \n",
    "            return np.nan\n",
    "        x = str(x).strip().lower()\n",
    "        if x.startswith('<'):\n",
    "            return 0.0\n",
    "        m = re.search(r'(\\d+)', x)\n",
    "        if m:\n",
    "            val = float(m.group(1))\n",
    "            return 10.0 if '+' in x else val\n",
    "        return np.nan\n",
    "    fe['emp_length_years'] = fe['Employment_length'].apply(emp_len_to_years).astype('float32')\n",
    "\n",
    "# grade → ordinal (A..G). Higher is better risk-wise (A highest)\n",
    "if 'grade' in fe.columns:\n",
    "    grade_order = {'g':1,'f':2,'e':3,'d':4,'c':5,'b':6,'a':7}\n",
    "    fe['grade_ord'] = fe['grade'].astype(str).str.lower().map(grade_order).astype('float32')\n",
    "\n",
    "# sub_grade → ordinal A1..G5 → 1..35 (higher = better)\n",
    "if 'sub_grade' in fe.columns:\n",
    "    def subgrade_to_ord(x: str) -> float:\n",
    "        if not isinstance(x, str) or len(x) < 2:\n",
    "            return np.nan\n",
    "        letter, num = x[0].upper(), x[1:]\n",
    "        if letter not in 'ABCDEFG' or not num.isdigit():\n",
    "            return np.nan\n",
    "        base = (ord(letter) - ord('A')) * 5\n",
    "        return float(base + int(num))  # A1..A5: 1..5, B1..B5: 6..10, ... G1..G5: 31..35\n",
    "    fe['sub_grade_ord'] = fe['sub_grade'].apply(subgrade_to_ord).astype('float32')\n",
    "\n",
    "added = [c for c in fe.columns if c.endswith(('_months','_years','_ord'))]\n",
    "print(\"Added (ordinal):\", added)\n",
    "print(\"Shape:\", fe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b053258e",
   "metadata": {},
   "source": [
    "### Date Decomposition\n",
    "\n",
    "Date fields (e.g., issue date, last payment date, settlement date) are decomposed into separate **year** and **month** components.  \n",
    "This transformation allows time-based grouping, trend analysis, and the derivation of temporal metrics such as credit history age.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c8a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing year/month. Shape: (9989, 31)\n"
     ]
    }
   ],
   "source": [
    "# Date decomposition (year, month, optional ages)\n",
    "\n",
    "date_cols = [\n",
    "    'issue_d','earliest_cr_line','last_pymnt_d',\n",
    "    'next_pymnt_d','last_credit_pull_d',\n",
    "    'debt_settlement_flag_date','settlement_date',\n",
    "    'sec_app_earliest_cr_line'\n",
    "]\n",
    "\n",
    "# LendingClub dates look like \"Dec-2015\"\n",
    "FMT = \"%b-%Y\"\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)  # silence the “Could not infer format” spam\n",
    "    for col in date_cols:\n",
    "        if col in fe.columns:\n",
    "            # strip just in case and parse with explicit format\n",
    "            dt = pd.to_datetime(fe[col].astype(str).str.strip(), format=FMT, errors=\"coerce\")\n",
    "            fe[col + \"_year\"]  = dt.dt.year.astype(\"float32\")\n",
    "            fe[col + \"_month\"] = dt.dt.month.astype(\"float32\")\n",
    "\n",
    "print(\"Done parsing year/month. Shape:\", fe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b8ab07",
   "metadata": {},
   "source": [
    "### Derived Time Feature: Credit History Age\n",
    "\n",
    "A new variable `credit_history_age_months` is computed as the difference in months between the loan issue date and the borrower's earliest credit line.  \n",
    "This feature measures the borrower’s credit experience and is useful for portfolio risk and maturity analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ad9baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added credit_history_age_months. Shape: (9989, 32)\n"
     ]
    }
   ],
   "source": [
    "# credit history age in months\n",
    "\n",
    "issue_col = 'issue_d'\n",
    "earliest_col = 'earliest_cr_line'\n",
    "\n",
    "# Explicit date parsing with format \"%b-%Y\"\n",
    "issue_dt = pd.to_datetime(fe[issue_col].astype(str).str.strip(), format=\"%b-%Y\", errors=\"coerce\")\n",
    "earl_dt  = pd.to_datetime(fe[earliest_col].astype(str).str.strip(), format=\"%b-%Y\", errors=\"coerce\")\n",
    "\n",
    "# Create mask for valid rows\n",
    "mask = issue_dt.notna() & earl_dt.notna()\n",
    "\n",
    "# Initialize column\n",
    "fe['credit_history_age_months'] = np.nan\n",
    "\n",
    "# Calculate difference in months\n",
    "months_diff = (\n",
    "    (issue_dt.dt.year[mask] - earl_dt.dt.year[mask]) * 12\n",
    "    + (issue_dt.dt.month[mask] - earl_dt.dt.month[mask])\n",
    ").astype('float32')\n",
    "\n",
    "# Assign and clean negatives\n",
    "fe.loc[mask, 'credit_history_age_months'] = months_diff\n",
    "fe.loc[fe['credit_history_age_months'] < 0, 'credit_history_age_months'] = np.nan\n",
    "\n",
    "print(\"Added credit_history_age_months. Shape:\", fe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820a29b",
   "metadata": {},
   "source": [
    "### Numeric Feature Transformations\n",
    "\n",
    "Numeric variables are standardized and transformed to improve interpretability and reduce skewness.  \n",
    "Transformations include:\n",
    "- **Log scaling** for highly skewed financial amounts  \n",
    "- **Ratio features** (e.g., payment-to-loan ratio, income-to-loan ratio)  \n",
    "- **Standard scaling** for comparability across KPIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abcb45a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added numeric transformations. Shape: (9989, 41)\n"
     ]
    }
   ],
   "source": [
    "# Select numeric features for transformation\n",
    "num_cols = fe.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Log transform for skewed features (add +1 to avoid log(0))\n",
    "log_features = ['loan_amnt', 'annual_inc', 'total_pymnt', 'total_rec_int', 'funded_amnt_inv']\n",
    "for col in log_features:\n",
    "    if col in fe.columns:\n",
    "        fe[col + '_log'] = np.log1p(fe[col])\n",
    "\n",
    "# Ratio features (relative to loan amount)\n",
    "if all(c in fe.columns for c in ['total_pymnt', 'loan_amnt']):\n",
    "    fe['payment_to_loan_ratio'] = fe['total_pymnt'] / fe['loan_amnt']\n",
    "\n",
    "if all(c in fe.columns for c in ['annual_inc', 'loan_amnt']):\n",
    "    fe['income_to_loan_ratio'] = fe['annual_inc'] / fe['loan_amnt']\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = ['int_rate', 'installment', 'annual_inc', 'dti']\n",
    "for col in scaled_features:\n",
    "    if col in fe.columns:\n",
    "        fe[col + '_scaled'] = scaler.fit_transform(fe[[col]])\n",
    "\n",
    "print(\"Added numeric transformations. Shape:\", fe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efd4c1",
   "metadata": {},
   "source": [
    "    ### Categorical Feature Encoding\n",
    "\n",
    "Categorical attributes are encoded as follows:\n",
    "- **Low-cardinality** variables (≤30 unique values) use one-hot encoding.  \n",
    "- **High-cardinality** variables use target encoding with respect to `loan_status`.  \n",
    "\n",
    "This ensures an optimal balance between interpretability and dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c4d81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns considered: ['home_ownership', 'purpose', 'addr_state']\n",
      "Low-cardinality columns (One-Hot Encoding): ['home_ownership', 'purpose']\n",
      "High-cardinality columns (kept as-is for KPIs): ['addr_state']\n",
      "Categorical encoding complete. Final shape: (9989, 54)\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL FEATURE ENCODING\n",
    "# Only apply encoding to truly categorical fields that have not already been\n",
    "# transformed through ordinal or date-based encodings.\n",
    "\n",
    "# 1. Explicitly define relevant categorical columns\n",
    "cat_cols = [\n",
    "    'home_ownership',\n",
    "    'verification_status',\n",
    "    'purpose',\n",
    "    'addr_state',\n",
    "    'application_type',\n",
    "]\n",
    "\n",
    "# Keep only columns that actually exist in the dataframe\n",
    "cat_cols = [c for c in cat_cols if c in fe.columns]\n",
    "print(\"Categorical columns considered:\", cat_cols)\n",
    "\n",
    "# 2. Split into low- and high-cardinality groups\n",
    "low_card_cols = [c for c in cat_cols if fe[c].nunique() <= 30]\n",
    "high_card_cols = [c for c in cat_cols if fe[c].nunique() > 30]\n",
    "\n",
    "print(\"Low-cardinality columns (One-Hot Encoding):\", low_card_cols)\n",
    "print(\"High-cardinality columns (kept as-is for KPIs):\", high_card_cols)\n",
    "\n",
    "# 3. Apply One-Hot Encoding to low-cardinality fields only\n",
    "fe = pd.get_dummies(fe, columns=low_card_cols, drop_first=True)\n",
    "\n",
    "print(\"Categorical encoding complete. Final shape:\", fe.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f6524",
   "metadata": {},
   "source": [
    "## Feature Selection & Export\n",
    "\n",
    "After completing all feature engineering steps (ordinal encoding, date decomposition, derived temporal metrics, and categorical processing), a final subset of features is selected to support loan-portfolio KPI calculation and downstream risk analytics.\n",
    "\n",
    "The selected features include:\n",
    "\n",
    "- Loan identifiers  \n",
    "- Borrower demographic and financial attributes  \n",
    "- Loan characteristics (e.g., term, interest rate, amount)  \n",
    "- Derived time-based features (e.g., issue year/month, credit history age)  \n",
    "- Encoded categorical variables  \n",
    "- Performance fields required for KPI computation  \n",
    "\n",
    "The resulting dataset is exported as `loan_portfolio_features.csv` and will be used in the subsequent KPI Calculation stage of the thesis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b9b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selected features: 22\n",
      "Final dataset shape: (9989, 22)\n"
     ]
    }
   ],
   "source": [
    "# === FEATURE SELECTION & EXPORT ===\n",
    "\n",
    "# 1. List of selected features (you can adjust)\n",
    "selected_features = [\n",
    "    # Identifiers\n",
    "    'id', 'member_id',\n",
    "\n",
    "    # Loan characteristics\n",
    "    'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
    "    'term_months', 'int_rate', 'installment',\n",
    "    'grade_ord', 'sub_grade_ord',\n",
    "    'emp_length_years', 'purpose',\n",
    "    \n",
    "    # Borrower financial profile\n",
    "    'annual_inc', 'dti', 'revol_bal', 'revol_util',\n",
    "    'inq_last_6mths', 'open_acc', 'total_acc',\n",
    "\n",
    "    # Temporal features\n",
    "    'issue_d_year', 'issue_d_month',\n",
    "    'earliest_cr_line_year', 'earliest_cr_line_month',\n",
    "    'credit_history_age_months',\n",
    "\n",
    "    # Categorical high-card columns left as-is\n",
    "    'addr_state',\n",
    "\n",
    "    # Performance (for KPIs)\n",
    "    'loan_status', 'total_pymnt', 'total_rec_prncp',\n",
    "]\n",
    "\n",
    "# 2. Keep only columns that exist\n",
    "selected_features = [c for c in selected_features if c in fe.columns]\n",
    "print(\"Final selected features:\", len(selected_features))\n",
    "\n",
    "# 3. Create trimmed dataframe\n",
    "fe_final = fe[selected_features].copy()\n",
    "\n",
    "print(\"Final dataset shape:\", fe_final.shape)\n",
    "\n",
    "# 4. Export\n",
    "output_path = DATA_DIR / \"fe_features.csv\"\n",
    "fe_final.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
